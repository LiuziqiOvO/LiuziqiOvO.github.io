**1. CGHit**: A Content-oriented Generative-hit  Framework for Content Delivery Networks；

International Conference on Networking, Architecture, and Storage (NAS) ，学生三作，主要负责工程开发和实验测试，以及论文写作。

**问题：**CDN节点命中率低，传统缓存策略只基于数据地址考虑局部性，例如图片的URL，无法感知对象实际内容，比如说同一图片的不同格式，不同清晰度会被按照不同文件存储。

**识别伪缺失：**例如，一次对低清晰度的A图片的请求，在CDN边缘节点不存在该文件，但存在该图片的高清版本。我们获取元数据，并基于伪缺失判断器（离线更新的决策树模型）和内容相似性哈希（DSTH模型）进行识别，在边界点直接生成对文件并返回。

**效果**：在腾讯CDN节点部署测试，平均延迟降低56.04%，回源带宽降低60.28%；在模拟器上，将CGHit与传统缓存算法（如LRU）结合，内容冗余率平均降低20%-25.2%。



**2. ɛ-LAP:** A Lightweight and Adaptive Cache Partitioning Scheme With Prudent Resizing Decisions for Content Delivery Networks；

IEEE Transactions on Cloud Computing（TCC），学生二作。主要负责工程开发，性能调优和实验测试。

**问题：**传统方法，如MRC（miss ratio curve）在CDN场景中，由于项目大小多样、应用数量庞大导致计算开销高、性能不稳定等问题。

一种轻量级自适应缓存分区方案 **ε-LAP**。根据命中率等元数据，通过在分区间转移存储容量优化资源分配；引入学习阈值参数 ε，分区按命中率的差异超过ɛ时触发调整。ɛ通过Lasso回归模型进行在线学习。智能判断分区调整时机，可以减少96.8%的调整。

**效果**：在腾讯PicCloud部署后，ɛ-LAP将缓存命中率提升9.34%，用户平均访问延迟降低12.5毫秒（约10%改善）。且CPU利用率仅增加0.3%，内存开销增加约50MB。







详细版：

以下是我参与的两个与AI相关的项目经历，重点介绍了AI模型实现的细节及其在内容分发网络（CDN）优化中的应用。

---

#### **CGHit: A Content-oriented Generative-hit Framework for Content Delivery Networks**
- **会议**：International Conference on Networking, Architecture, and Storage (NAS)，学生第三作者。
- **问题**：传统CDN缓存策略仅基于数据地址（如URL）考虑局部性，无法感知对象的实际内容。例如，同一张图片的不同格式（如JPEG和PNG）或不同清晰度版本（如高清和低清）会被视为不同文件分别存储，导致缓存冗余和命中率低下。
- **解决方案与AI模型实现**：
  - **伪缺失识别**：针对“伪缺失”场景（即请求的数据在缓存中不存在，但存在内容相似或相关的缓存数据），我们设计了一个基于AI的伪缺失判断模块。具体实现上，通过获取请求的元数据（如文件名、参数）并结合**内容相似性哈希（DSTH模型）**进行识别。DSTH模型是一种深度自学习哈希算法，通过生成128位相似性哈希码，快速比较请求数据与缓存数据的内容相似度。例如，当用户请求低清晰度图片A时，若缓存中存在其高清版本，DSTH模型计算两者的哈希距离（Hamming Distance），若低于阈值，则判定为伪缺失。
  - **生成模型**：在边缘节点利用闲置计算资源，基于缓存中的相似数据生成请求数据。生成过程根据伪缺失场景分为多种情况：
    - 对于图像数据，采用开源图像处理库（如imglib），实现缩放（scaling）、格式转换（format conversion）等操作。例如，从高清图片生成低清版本，生成时间通常控制在150毫秒以内。
    - 对于块数据（block data），通过提取（extraction）和拼接（splicing）操作生成目标数据块，生成时间约1毫秒。
  - **决策模型**：为避免频繁生成带来的计算负担，我们引入了一个**决策树模型**预测伪缺失数据的未来访问频率。决策树基于特征（如文件类型、大小、访问频率、最近性等）进行训练，离线更新以确保主业务性能。若模型预测数据将被频繁访问，则异步从数据中心获取原始数据并写入缓存；否则直接生成数据响应请求。实验表明，决策树在缓存决策问题上的准确性优于朴素贝叶斯、神经网络等模型，且计算开销低、决策速度快。
- **效果**：在腾讯CDN节点（PicCloud）部署测试，平均访问延迟降低56.04%（从231.07毫秒降至约101毫秒），回源带宽降低60.28%。在模拟器上，CGHit与传统缓存算法（如LRU）结合，进一步减少了延迟和带宽使用，内容冗余率平均降低20%-25.2%。

---

#### **ɛ-LAP: A Lightweight and Adaptive Cache Partitioning Scheme With Prudent Resizing Decisions for Content Delivery Networks**
- **期刊**：IEEE Transactions on Cloud Computing (TCC)，学生第二作者。
- **问题**：传统缓存分区方法（如基于Miss Ratio Curve, MRC的方案）在CDN场景中，由于项目大小多样（从KB到GB不等）、应用数量庞大（超过10^4个），导致计算开销高（复杂度达O(P×N^2)级别）且性能不稳定，特别是在大缓存（如TB级）和动态负载下。
- **解决方案与AI模型实现**：
  - **分区调整机制**：提出ɛ-LAP方案，通过为每个分区配备影子缓存（shadow cache），记录元数据（如命中次数），并根据影子缓存中的命中率（Rank = cnt_i / S_i，其中cnt_i为命中次数，S_i为影子缓存大小）对分区排序。以粒度单位（G-Size，例如20MB或32MB）在分区间转移存储容量，从命中率较低的分区（如第N-k+1个）转移到命中率较高的分区（如第k个），优化资源分配。
  - **学习阈值ɛ**：引入一个学习阈值参数ɛ，通过AI模型智能判断是否执行分区调整。具体实现上，当一对分区的Rank差异超过ɛ时（即 G × (cnt_i/S_i - cnt_j/S_j) > ɛ），才触发调整。ɛ通过**Lasso回归模型**根据应用请求比例（如前三大应用的请求占比）进行在线学习。例如，在Trace-BJ数据集上，训练样本显示ɛ与请求分布相关，最终预测ɛ≈6.6，与实际最优值接近。这种方法减少了96.8%的无效调整操作，大幅降低计算开销（复杂度降至O(N×log N)）。
  - **模型优化**：通过分析调整过程中无效缓存空间（R-Size）与命中率的关系，确定合适的G-Size。例如，实验表明，当G-Size过大或过小时，命中率下降；通过调整G-Size至数据大小分布的99%分位点（如32MB），实现最佳性能。
- **效果**：在腾讯PicCloud部署后，ɛ-LAP将缓存命中率提升9.34%（从基线LRU的水平提升），用户平均访问延迟降低12.5毫秒（约10%改善）。实验表明，ɛ-LAP在命中率、延迟和负载适应性上均优于其他先进方案（如LPCA、KPart），且CPU利用率仅增加0.3%，内存开销增加0.05GB，表现出轻量级特性。

---

### 总结
- **CGHit**通过内容相似性哈希（DSTH）和决策树模型实现了伪缺失识别与数据生成，利用AI技术显著提升了CDN的命中率和响应速度。
- **ɛ-LAP**利用Lasso回归学习阈值ɛ，结合影子缓存的轻量级分区调整机制，优化了CDN资源分配，兼顾效率与性能。

这两个项目展示了AI在CDN优化中的创新应用，尤其是在内容感知和自适应资源管理方面的突破。